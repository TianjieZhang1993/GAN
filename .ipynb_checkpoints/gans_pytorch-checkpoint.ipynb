{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.nn import Module, Sequential, Conv2d, ConvTranspose2d, LeakyReLU, BatchNorm2d, ReLU, Tanh, Sigmoid, BCELoss \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "# path to the image directory\n",
    "dir_data  = \"C:/Users/tjzha/OneDrive/Documents/GitHub/GANs_Pytorch/Humans\"\n",
    " \n",
    "# setting image shape to 32x32\n",
    "img_shape = (32, 32, 3)\n",
    " \n",
    "# listing out all file names\n",
    "nm_imgs   = np.sort(os.listdir(dir_data))\n",
    "nm_imgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "for file in nm_imgs:\n",
    "    try:\n",
    "        img = Image.open(dir_data+'/'+file)\n",
    "        img = img.convert('RGB')\n",
    "        img = img.resize((32,32))\n",
    "        img = np.asarray(img)/255\n",
    "        X_train.append(img)\n",
    "    except:\n",
    "        print(\"something went wrong\")\n",
    " \n",
    "X_train = np.array(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import asarray\n",
    "from numpy import savez_compressed\n",
    " \n",
    "# save to npy file\n",
    "savez_compressed('kaggle_images_32x32.npz', X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dict of arrays\n",
    "dict_data = np.load('kaggle_images_32x32.npz')\n",
    " \n",
    "# extract the first array\n",
    "data = dict_data['arr_0']\n",
    " \n",
    "# print the array\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1609933922674
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1609933925191
    }
   },
   "outputs": [],
   "source": [
    "# plot images in a nxn grid\n",
    "def plot_images(imgs, grid_size = 5):\n",
    "    \"\"\"\n",
    "    imgs: vector containing all the numpy images\n",
    "    grid_size: 2x2 or 5x5 grid containing images\n",
    "    \"\"\"\n",
    "    \n",
    "    fig = plt.figure(figsize = (8, 8))\n",
    "    columns = rows = grid_size\n",
    "    plt.title(\"Training Images\")\n",
    "\n",
    "    for i in range(1, columns*rows +1):\n",
    "        plt.axis(\"off\")\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(imgs[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1609933928970
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# load the numpy vector containing image representations\n",
    "imgs = np.load('kaggle_images_32x32.npz')\n",
    "\n",
    "# to check all the files contained in it\n",
    "imgs.files\n",
    "\n",
    "# this is where all our images are saved\n",
    "imgs['arr_0'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1609843980912
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# pls ignore the poor quality of the images as we are working with 32x32 sized images.\n",
    "plot_images(imgs['arr_0'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1609933936083
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Always good to check if gpu support available or not\n",
    "\n",
    "dev = 'cuda:0' if torch.cuda.is_available() == True else 'cpu'\n",
    "device = torch.device(dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1609844329408
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# To check the device name\n",
    "print ('Current cuda device name ', torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1609933942885
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Preparing custom dataset class - https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class\n",
    "\n",
    "\n",
    "class HumanFacesDataset(Dataset):\n",
    "    \"\"\"Human Faces dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, npz_imgs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            npz_imgs (string): npz file with all the images (created in gan.ipynb)\n",
    "        \"\"\"\n",
    "        self.imgs = npz_imgs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        image = self.imgs[idx]\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1609936286021
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "imgs['arr_0'][0].dtype # it will output float 64 i.e. double\n",
    "\n",
    "# must convert it to float 32 (which is same as model weights)\n",
    "np.float32(imgs['arr_0']).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1609942974998
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Preparing dataloader for training\n",
    "\n",
    "transpose_imgs = np.transpose( # imp step to convert image size from (7312, 32,32,3) to (7312, 3,32,32)\n",
    "    np.float32(imgs['arr_0']), # imp step to convert double -> float (by default numpy input uses double as data type)\n",
    "    (0, 3,1,2) # tuple to describe how to rearrange the dimensions\n",
    "    ) \n",
    "\n",
    "dset = HumanFacesDataset(transpose_imgs) # passing the npz variable to the constructor class\n",
    "batch_size = 32\n",
    "shuffle = True\n",
    "\n",
    "dataloader = DataLoader(dataset = dset, batch_size = batch_size, shuffle = shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1609933993753
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Defining the Generator class\n",
    "\n",
    "class Generator(Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        # calling constructor of parent class\n",
    "        super().__init__()\n",
    "\n",
    "        self.gen = Sequential(\n",
    "          ConvTranspose2d(in_channels = 100, out_channels = 512 , kernel_size = 4, stride = 1, padding = 0, bias = False),\n",
    "          # the output from the above will be b_size ,512, 4,4\n",
    "          BatchNorm2d(num_features = 512), # From an input of size (b_size, C, H, W), pick num_features = C\n",
    "          ReLU(inplace = True),\n",
    "\n",
    "          ConvTranspose2d(in_channels = 512, out_channels = 256 , kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "          # the output from the above will be b_size ,256, 8,8\n",
    "          BatchNorm2d(num_features = 256),\n",
    "          ReLU(inplace = True),\n",
    "\n",
    "          ConvTranspose2d(in_channels = 256, out_channels = 128 , kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "          # the output from the above will be b_size ,128, 16,16\n",
    "          BatchNorm2d(num_features = 128),\n",
    "          ReLU(inplace = True),\n",
    "\n",
    "          ConvTranspose2d(in_channels = 128, out_channels = 3 , kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "          # the output from the above will be b_size ,3, 32,32\n",
    "          Tanh()\n",
    "        \n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.gen(input)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1609933996999
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "netG = Generator().to(device)\n",
    "\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1609934000598
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# As an example, to show the shape of the output from the generator -  must be an image\n",
    "t = torch.randn(2, 100, 1, 1)\n",
    "netG(t.to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1609934015728
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == ConvTranspose2d:\n",
    "        nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    elif type(m) == BatchNorm2d:\n",
    "        nn.init.normal_(m.weight, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1609934026819
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Let's initialize the weights randomly (for a single layer)\n",
    "netG.apply(init_weights)\n",
    "\n",
    "# Print the model\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1609934819684
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Defining the Discriminator class\n",
    "\n",
    "class Discriminator(Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__()\n",
    "        self.dis = Sequential(\n",
    "\n",
    "            # input is (3, 32, 32)\n",
    "            Conv2d(in_channels = 3, out_channels = 32, kernel_size = 4, stride = 2, padding = 1, bias=False),\n",
    "            # ouput from above layer is b_size, 32, 16, 16\n",
    "            LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            Conv2d(in_channels = 32, out_channels = 32*2, kernel_size = 4, stride = 2, padding = 1, bias=False),\n",
    "            # ouput from above layer is b_size, 32*2, 8, 8\n",
    "            BatchNorm2d(32 * 2),\n",
    "            LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            Conv2d(in_channels = 32*2, out_channels = 32*4, kernel_size = 4, stride = 2, padding = 1, bias=False),\n",
    "            # ouput from above layer is b_size, 32*4, 4, 4\n",
    "            BatchNorm2d(32 * 4),\n",
    "            LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            Conv2d(in_channels = 32*4, out_channels = 32*8, kernel_size = 4, stride = 2, padding = 1, bias=False),\n",
    "            # ouput from above layer is b_size, 256, 2, 2\n",
    "            # NOTE: spatial size of this layer is 2x2, hence in the final layer, the kernel size must be 2 instead (or smaller than) 4\n",
    "            BatchNorm2d(32 * 8),\n",
    "            LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            Conv2d(in_channels = 32*8, out_channels = 1, kernel_size = 2, stride = 2, padding = 0, bias=False),\n",
    "            # ouput from above layer is b_size, 1, 1, 1\n",
    "            Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.dis(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1609934034847
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# As an example, to show the shape of the output from the generator -  must be an integer\n",
    "t = torch.randn(2, 3, 32, 32)\n",
    "\n",
    "netD = Discriminator().to(device)\n",
    "netD(t.to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1609934037909
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# initializing the weights\n",
    "netD.apply(init_weights)\n",
    "\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1609934062844
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Setting up otimizers for both Generator and Discriminator\n",
    "\n",
    "opt_D = optim.Adam(netD.parameters(), lr = 0.0002, betas= (0.5, 0.999))\n",
    "opt_G = optim.Adam(netG.parameters(), lr = 0.0002, betas= (0.5, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1609934072255
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Setting up the loss function - BCELoss (to check how far the predicted value is from real value)\n",
    "\n",
    "loss = BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1609872854223
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# TRAINING GANS\n",
    "epochs = 1000\n",
    "\n",
    "# going over the entire dataset 10 times\n",
    "for e in range(epochs):\n",
    "    \n",
    "    # pick each batch b of input images: shape of each batch is (32, 3, 32, 32)\n",
    "    for i, b in enumerate(dataloader):\n",
    "\n",
    "        ##########################\n",
    "        ## Update Discriminator ##\n",
    "        ##########################\n",
    "\n",
    "        # Loss on real images\n",
    "        \n",
    "        # clear the gradient\n",
    "        opt_D.zero_grad() # set the gradients to 0 at start of each loop because gradients are accumulated on subsequent backward passes\n",
    "        # compute the D model output\n",
    "        yhat = netD(b.to(device)).view(-1) # view(-1) reshapes a 4-d tensor of shape (2,1,1,1) to 1-d tensor with 2 values only\n",
    "        # specify target labels or true labels\n",
    "        target = torch.ones(len(b), dtype=torch.float, device=device)\n",
    "        # calculate loss\n",
    "        loss_real = loss(yhat, target)\n",
    "        # calculate gradients -  or rather accumulation of gradients on loss tensor\n",
    "        loss_real.backward()\n",
    "\n",
    "        # Loss on fake images\n",
    "\n",
    "        # generate batch of fake images using G\n",
    "        # Step1: creating noise to be fed as input to G\n",
    "        noise = torch.randn(len(b), 100, 1, 1, device = device)\n",
    "        # Step 2: feed noise to G to create a fake img (this will be reused when updating G)\n",
    "        fake_img = netG(noise) \n",
    "\n",
    "        # compute D model output on fake images\n",
    "        yhat = netD.cuda()(fake_img.detach()).view(-1) # .cuda() is essential because our input i.e. fake_img is on gpu but model isnt (runtimeError thrown); detach is imp: Basically, only track steps on your generator optimizer when training the generator, NOT the discriminator. \n",
    "        # specify target labels\n",
    "        target = torch.zeros(len(b), dtype=torch.float, device=device)\n",
    "        # calculate loss\n",
    "        loss_fake = loss(yhat, target)\n",
    "        # calculate gradients\n",
    "        loss_fake.backward()\n",
    "\n",
    "        # total error on D\n",
    "        loss_disc = loss_real + loss_fake\n",
    "\n",
    "        # Update weights of D\n",
    "        opt_D.step()\n",
    "\n",
    "        ##########################\n",
    "        #### Update Generator ####\n",
    "        ##########################\n",
    "\n",
    "        # clear gradient\n",
    "        opt_G.zero_grad()\n",
    "        # pass fake image through D\n",
    "        yhat = netD.cuda()(fake_img).view(-1)\n",
    "        # specify target variables - remember G wants D *to think* these are real images so label is 1\n",
    "        target = torch.ones(len(b), dtype=torch.float, device=device)\n",
    "        # calculate loss\n",
    "        loss_gen = loss(yhat, target)\n",
    "        # calculate gradients\n",
    "        loss_gen.backward()\n",
    "        # update weights on G\n",
    "        opt_G.step()\n",
    "\n",
    "\n",
    "        ####################################\n",
    "        #### Plot some Generator images ####\n",
    "        ####################################\n",
    "\n",
    "        # during every epoch, print images at every 10th iteration.\n",
    "        if i% 10 == 0:\n",
    "            # convert the fake images from (b_size, 3, 32, 32) to (b_size, 32, 32, 3) for plotting \n",
    "            img_plot = np.transpose(fake_img.detach().cpu(), (0,2,3,1)) # .detach().cpu() is imp for copying fake_img tensor to host memory first\n",
    "            plot_images(img_plot)\n",
    "            print(\"********************\")\n",
    "            print(\" Epoch %d and iteration %d \" % (e, i))\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
